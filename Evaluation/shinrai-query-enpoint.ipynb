{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a47604-4b79-4dbe-836a-15d25ad9979f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c786351-69f0-4719-a955-d301339a8809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils/\") # go to parent dir\n",
    "from query_endpoint import *\n",
    "from parse_response import *\n",
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "400cab55-6e97-45c6-98bb-7513b9def634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"huggingface-text2text-flan-t5-xl\"\n",
    "endpoint_name = f\"KC-ShinrAI-{model_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f401d-2091-4e92-b5de-e067e76913c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47af6a99-c60b-4d9a-bed7-5211d5706ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:\n",
      "input text: Translate to German:  My name is Arthur\n",
      "generated text: \u001b[1mIch bin Arthur.\u001b[0m\n",
      "\n",
      "Inference:\n",
      "input text: A step by step recipe to make bolognese pasta:\n",
      "generated text: \u001b[1mIn a large saucepan, combine the ground beef, onion, garlic, tomato paste, tomato\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "text1 = \"Translate to German:  My name is Arthur\"\n",
    "text2 = \"A step by step recipe to make bolognese pasta:\"\n",
    "\n",
    "for text in [text1, text2]:\n",
    "    query_response = query_endpoint(text.encode(\"utf-8\"), endpoint_name=endpoint_name)\n",
    "    generated_text = parse_response(query_response)\n",
    "    print(\n",
    "        f\"Inference:{newline}\"\n",
    "        f\"input text: {text}{newline}\"\n",
    "        f\"generated text: {bold}{generated_text}{unbold}{newline}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e7221-f1aa-490f-b1b7-9c87800e4752",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query with JSON\n",
    "\n",
    "***\n",
    "This model also supports many advanced parameters while performing inference. They include:\n",
    "\n",
    "* **max_length:** Model generates text until the output length (which includes the input context length) reaches `max_length`. If specified, it must be a positive integer.\n",
    "* **num_return_sequences:** Number of output sequences returned. If specified, it must be a positive integer.\n",
    "* **num_beams:** Number of beams used in the greedy search. If specified, it must be integer greater than or equal to `num_return_sequences`.\n",
    "* **no_repeat_ngram_size:** Model ensures that a sequence of words of `no_repeat_ngram_size` is not repeated in the output sequence. If specified, it must be a positive integer greater than 1.\n",
    "* **temperature:** Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If `temperature` -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
    "* **early_stopping:** If True, text generation is finished when all beam hypotheses reach the end of sentence token. If specified, it must be boolean.\n",
    "* **do_sample:** If True, sample the next word as per the likelihood. If specified, it must be boolean.\n",
    "* **top_k:** In each step of text generation, sample from only the `top_k` most likely words. If specified, it must be a positive integer.\n",
    "* **top_p:** In each step of text generation, sample from the smallest possible set of words with cumulative probability `top_p`. If specified, it must be a float between 0 and 1.\n",
    "* **seed:** Fix the randomized state for reproducibility. If specified, it must be an integer.\n",
    "\n",
    "We may specify any subset of the parameters mentioned above while invoking an endpoint. Next, we show an example of how to invoke endpoint with these arguments\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d675b3-7df0-464c-b4ab-d3a9fdaa6bae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To make a pizza, place the dough on a baking sheet. Sprinkle with salt and pepper. Bake for 20 minutes at 400 degrees Fahrenheit.', 'Place the pizza dough on a baking sheet. Spread the pizza sauce over the dough. Top with the cheese. Bake in the oven at 450 degrees for 15 minutes.', 'To make a pizza, you first need to gather your ingredients. You will need a pizza stone, flour, and oil. You will also need a pizza peel, a pizza cutter, and a pizza stone. You will']\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"text_inputs\": \"Tell me the steps to make a pizza\",\n",
    "    \"max_length\": 50,\n",
    "    \"num_return_sequences\": 3,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    json.dumps(payload).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "generated_texts = parse_response_multiple_texts(query_response)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e7304d-1179-41c1-af50-eec75a675ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
